{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4f78bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random starting synaptic weights: \n",
      "[[-0.16595599]\n",
      " [ 0.44064899]\n",
      " [-0.99977125]]\n",
      "New synaptic weights after training: \n",
      "[[ 9.67299303]\n",
      " [-0.2078435 ]\n",
      " [-4.62963669]]\n",
      "Considering new situation [1, 0, 0] -> ?: \n",
      "[0.99993704]\n"
     ]
    }
   ],
   "source": [
    "from numpy import exp, array, random, dot\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self):\n",
    "        # Seed the random number generator, so it generates the same numbers\n",
    "        # every time the program runs.\n",
    "        random.seed(1)\n",
    "\n",
    "        # We model a single neuron, with 3 input connections and 1 output connection.\n",
    "        # We assign random weights to a 3 x 1 matrix, with values in the range -1 to 1\n",
    "        # and mean 0.\n",
    "        self.synaptic_weights = 2 * random.random((3, 1)) - 1\n",
    "\n",
    "    # The Sigmoid function, which describes an S shaped curve.\n",
    "    # We pass the weighted sum of the inputs through this function to\n",
    "    # normalize them between 0 and 1.\n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + exp(-x))\n",
    "\n",
    "    # The derivative of the Sigmoid function.\n",
    "    # This is the gradient of the Sigmoid curve.\n",
    "    # It indicates how confident we are about the existing weight.\n",
    "    def __sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    # We train the neural network through a process of trial and error.\n",
    "    # Adjusting the synaptic weights each time.\n",
    "    def train(self, training_set_inputs, training_set_outputs, number_of_training_iterations):\n",
    "        for iteration in range(number_of_training_iterations):\n",
    "            # Pass the training set through our neural network (a single neuron).\n",
    "            output = self.think(training_set_inputs)\n",
    "\n",
    "            # Calculate the error (The difference between the desired output\n",
    "            # and the predicted output).\n",
    "            error = training_set_outputs - output\n",
    "\n",
    "            # Multiply the error by the input and again by the gradient of the Sigmoid curve.\n",
    "            # This means less confident weights are adjusted more.\n",
    "            # This means inputs, which are zero, do not cause changes to the weights.\n",
    "            adjustment = dot(training_set_inputs.T, error * self.__sigmoid_derivative(output))\n",
    "\n",
    "            # Adjust the weights.\n",
    "            self.synaptic_weights += adjustment\n",
    "\n",
    "    # The neural network thinks.\n",
    "    def think(self, inputs):\n",
    "        # Pass inputs through our neural network (our single neuron).\n",
    "        return self.__sigmoid(dot(inputs, self.synaptic_weights))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize a single neuron neural network.\n",
    "    neural_network = NeuralNetwork()\n",
    "\n",
    "    print(\"Random starting synaptic weights: \")\n",
    "    print(neural_network.synaptic_weights)\n",
    "\n",
    "    # The training set. We have 4 examples, each consisting of 3 input values\n",
    "    # and 1 output value.\n",
    "    training_set_inputs = array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])\n",
    "    training_set_outputs = array([[0, 1, 1, 0]]).T\n",
    "\n",
    "    # Train the neural network using a training set.\n",
    "    # Do it 10,000 times and make small adjustments each time.\n",
    "    neural_network.train(training_set_inputs, training_set_outputs, 10000)\n",
    "\n",
    "    print(\"New synaptic weights after training: \")\n",
    "    print(neural_network.synaptic_weights)\n",
    "\n",
    "    # Test the neural network with a new situation.\n",
    "    print(\"Considering new situation [1, 0, 0] -> ?: \")\n",
    "    print(neural_network.think(array([1, 0, 0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9f1fbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.245e+01 1.570e+01 8.257e+01 4.771e+02 1.278e-01 1.700e-01 1.578e-01\n",
      " 8.089e-02 2.087e-01 7.613e-02 3.345e-01 8.902e-01 2.217e+00 2.719e+01\n",
      " 7.510e-03 3.345e-02 3.672e-02 1.137e-02 2.165e-02 5.082e-03 1.547e+01\n",
      " 2.375e+01 1.034e+02 7.416e+02 1.791e-01 5.249e-01 5.355e-01 1.741e-01\n",
      " 3.985e-01 1.244e-01]\n",
      "(569, 30)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
      "acuracy: 0.9649122807017544\n",
      "precision: 0.9642857142857143\n",
      "recall 0.9782608695652174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96        90\n",
      "           1       0.96      0.98      0.97       138\n",
      "\n",
      "    accuracy                           0.96       228\n",
      "   macro avg       0.97      0.96      0.96       228\n",
      "weighted avg       0.96      0.96      0.96       228\n",
      "\n",
      "[0 1 2 ... 5 7 9]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    " \n",
    "cancer_data = datasets.load_breast_cancer()\n",
    "print(cancer_data.data[5])\n",
    "print(cancer_data.data.shape) \n",
    "#target set \n",
    "print(cancer_data.target)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer_data = datasets.load_breast_cancer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer_data.data, cancer_data.target, test_size=0.4,random_state=109)\n",
    "from sklearn import svm\n",
    "#create a classifier\n",
    "cls = svm.SVC(kernel=\"linear\")\n",
    "#train the model\n",
    "cls.fit(X_train,y_train)\n",
    "#predict the response\n",
    "pred = cls.predict(X_test)\n",
    "from sklearn import metrics\n",
    "#accuracy\n",
    "print(\"acuracy:\", metrics.accuracy_score(y_test,y_pred=pred))\n",
    "#precision score\n",
    "print(\"precision:\", metrics.precision_score(y_test,y_pred=pred))\n",
    "#recall score\n",
    "print(\"recall\" , metrics.recall_score(y_test,y_pred=pred))\n",
    "print(metrics.classification_report(y_test, y_pred=pred))\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "#loading the dataset\n",
    "letters = datasets.load_digits()\n",
    "#generating the classifier\n",
    "clf = svm.SVC(gamma=0.001, C=100)\n",
    "#training the classifier\n",
    "X,y = letters.data[:-10], letters.target[:-10]\n",
    "clf.fit(X,y)\n",
    "#predicting the output \n",
    "print(clf.predict(letters.data[:-10]))\n",
    "plt.imshow(letters.images[6], interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bcde256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     5.1  3.5  1.4  0.2     Iris-setosa\n",
      "0    4.9  3.0  1.4  0.2     Iris-setosa\n",
      "1    4.7  3.2  1.3  0.2     Iris-setosa\n",
      "2    4.6  3.1  1.5  0.2     Iris-setosa\n",
      "3    5.0  3.6  1.4  0.2     Iris-setosa\n",
      "4    5.4  3.9  1.7  0.4     Iris-setosa\n",
      "..   ...  ...  ...  ...             ...\n",
      "144  6.7  3.0  5.2  2.3  Iris-virginica\n",
      "145  6.3  2.5  5.0  1.9  Iris-virginica\n",
      "146  6.5  3.0  5.2  2.0  Iris-virginica\n",
      "147  6.2  3.4  5.4  2.3  Iris-virginica\n",
      "148  5.9  3.0  5.1  1.8  Iris-virginica\n",
      "\n",
      "[149 rows x 5 columns]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Class'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# label1 = dataset.iloc[:, 0:4].values\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# label2 = dataset.iloc[:, 4].values\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m label1 \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m label2 \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Splitting the dataset into the Training set and Test set\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5112\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5122\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5256\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5259\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5260\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5261\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5262\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5263\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5264\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5265\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5266\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6699\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6700\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Class'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "\n",
    "# Define column names\n",
    "cls = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n",
    "\n",
    "# Read the data set\n",
    "dataset = pd.read_csv(url, names=cls)\n",
    "# label1 = dataset.iloc[:, 0:4].values\n",
    "# label2 = dataset.iloc[:, 4].values\n",
    "label1 = dataset.drop(columns='Class')\n",
    "label2 = dataset ['Class']\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "label1_train, label1_test, label2_train, label2_test = train_test_split(label1, label2, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "label1_train = scaler.fit_transform(label1_train)\n",
    "label1_test = scaler.transform(label1_test)\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(random_state = 0)\n",
    "model.fit(label1_train, label2_train)\n",
    "prediction = model.predict(label1_test)\n",
    "\n",
    "# Confusion Matrix and Accuracy\n",
    "matrix = confusion_matrix(label2_test, prediction)\n",
    "print(matrix)\n",
    "score = accuracy_score(label2_test, prediction)\n",
    "print(score)\n",
    "\n",
    "# LDA\n",
    "analysis = LDA(n_components = 2)\n",
    "label1_train = analysis.fit_transform(label1_train, label2_train)\n",
    "label1_test = analysis.transform(label1_test)\n",
    "\n",
    "# Logistic Regression after LDA\n",
    "model = LogisticRegression(random_state = 0)\n",
    "model.fit(label1_train, label2_train)\n",
    "prediction = model.predict(label1_test)\n",
    "\n",
    "# Confusion Matrix and Accuracy after LDA\n",
    "matrix = confusion_matrix(label2_test, prediction)\n",
    "print(matrix)\n",
    "score = accuracy_score(label2_test, prediction)\n",
    "print(score)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components = 2)\n",
    "label1_train = pca.fit_transform(label1_train, label2_train)\n",
    "label1_test = pca.transform(label1_test)\n",
    "\n",
    "# Logistic Regression after PCA\n",
    "model = LogisticRegression(random_state = 0)\n",
    "model.fit(label1_train, label2_train)\n",
    "prediction = model.predict(label1_test)\n",
    "\n",
    "# Confusion Matrix and Accuracy after PCA\n",
    "matrix = confusion_matrix(label2_test, prediction)\n",
    "print(matrix)\n",
    "score = accuracy_score(label2_test, prediction)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe198f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
